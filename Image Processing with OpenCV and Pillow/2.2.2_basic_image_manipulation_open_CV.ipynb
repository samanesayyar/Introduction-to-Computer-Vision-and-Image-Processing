{"cells":[{"cell_type":"markdown","id":"1961b0ac-e3c0-4589-ae40-66700357b003","metadata":{},"outputs":[],"source":["<p>\n","    <a href=\"https://skills.network\" target=\"_blank\">\n","    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\">\n","    </a>\n","</p>\n"]},{"cell_type":"markdown","id":"5a853202-ca82-455d-9416-464500101f4c","metadata":{},"outputs":[],"source":["**<h1> Manipulating Images </h1>**\n"]},{"cell_type":"markdown","id":"836b7624-955e-4030-972f-e2076f7b085f","metadata":{},"outputs":[],"source":["Estimated time needed: **30** minutes\n"]},{"cell_type":"markdown","id":"9e07174c-66f3-4366-8adc-f2f6fc49d3fe","metadata":{},"outputs":[],"source":["<h2>Objectives</h2>\n"]},{"cell_type":"markdown","id":"7d770951-4f4d-4be3-985d-6ef6f0982c73","metadata":{},"outputs":[],"source":["In this lab, you will learn how to manipulate images, OpenCV image Arrays. You will learn how to copy an image to avoid aliasing. We will cover flipping images and cropping images. You will also learn to change pixel images; this will allow you to draw shapes, write text and superimpose images over other images.\n"]},{"cell_type":"markdown","id":"b63677db-667f-404d-97d2-a459a1b77be5","metadata":{},"outputs":[],"source":["<ul>\n","    <li><a href='#MI'>Manipulating Images </a>\n","        <ul>\n","            <li>Copying Images  </li>\n","            <li>Fliping Images </li>\n","            <li>Cropping an Image </li>\n","            <li>Changing Specific Image Pixels </li>\n","     \n","  \n","    \n","</ul>\n"]},{"cell_type":"markdown","id":"66321b97-4638-478f-83bf-ef1ef95ed889","metadata":{},"outputs":[],"source":["----\n"]},{"cell_type":"markdown","id":"d7c53e4f-63b1-476f-bcf1-04dca8d6a53a","metadata":{},"outputs":[],"source":["Download the images for the lab\n"]},{"cell_type":"code","id":"9b137bca-2cd6-4a00-ab1e-d1ea441d72cf","metadata":{},"outputs":[],"source":["!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/cat.png -O cat.png\n!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/lenna.png -O lenna.png\n!wget https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-CV0101EN-SkillsNetwork/images%20/images_part_1/baboon.png -O baboon.png"]},{"cell_type":"markdown","id":"bf21878b-7ea8-49d5-949a-a3632059aeac","metadata":{},"outputs":[],"source":["We will be using these imported functions in the lab\n"]},{"cell_type":"code","id":"d42fb7b5-2563-484f-aa77-13a2640cf320","metadata":{},"outputs":[],"source":["import matplotlib.pyplot as plt\nimport cv2\nimport numpy as np"]},{"cell_type":"markdown","id":"74ebb585-173b-465e-ae1a-d19585fa02c0","metadata":{},"outputs":[],"source":["## Copying Images\n"]},{"cell_type":"markdown","id":"7dcca005-a115-4d3a-86b2-d57a1066990d","metadata":{},"outputs":[],"source":["If you want to reassign an array to another variable, you should use the `copy` method. If we do not apply the method `copy()`, the variable will point to the same location in memory. Consider the following array:\n"]},{"cell_type":"code","id":"ac1a4e68-fe39-4d67-a19e-84fb8912e678","metadata":{},"outputs":[],"source":["baboon = cv2.imread(\"baboon.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(cv2.cvtColor(baboon, cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"markdown","id":"b007aeef-f9f9-46b8-94b7-7db5e9342f28","metadata":{},"outputs":[],"source":["If we do not apply the method `copy()`, the new variable will point to the same location in memory:\n"]},{"cell_type":"code","id":"0e5ddc95-129b-4200-9d29-9ca2747a42d3","metadata":{},"outputs":[],"source":["A = baboon"]},{"cell_type":"markdown","id":"004a8143-c011-45be-b23c-3c4603b06194","metadata":{},"outputs":[],"source":["we use the `id` function to find the object's memory address; we see it is the same as the original array.\n"]},{"cell_type":"code","id":"cfe5cc30-bab3-4ab2-bc03-c8f148da1793","metadata":{},"outputs":[],"source":["id(A)==id(baboon)\nid(A)"]},{"cell_type":"markdown","id":"cd820ccc-3567-464c-a6ca-f1a98a7dcd08","metadata":{},"outputs":[],"source":["If we apply the method `copy()</coode>, the memory address is different \n"]},{"cell_type":"code","id":"6a0f616b-87f7-4361-be6d-f68237465d4e","metadata":{},"outputs":[],"source":["B = baboon.copy()\nid(B)==id(baboon)"]},{"cell_type":"markdown","id":"91e2e773-7e84-412f-90a2-e6053eb71b6c","metadata":{},"outputs":[],"source":["When we do not apply the method <code>copy()</code>, the variable will point to the same location in memory. Consider the array <code>baboon</code>, if we set all its values to zero, then all the values in <code>A</code> will be zero. This is because <code>baboon</code> and <code>A</code> point to the same place in memory, but <code>B</code> will not be affected. \n"]},{"cell_type":"code","id":"1efa2696-65f8-463f-9e55-0b4ca4183c98","metadata":{},"outputs":[],"source":["baboon[:,:,] = 0"]},{"cell_type":"code","id":"10b1f0ad-db9e-4fdd-ac12-c4c3cadbb8b0","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\nplt.subplot(121)\nplt.imshow(cv2.cvtColor(baboon, cv2.COLOR_BGR2RGB))\nplt.title(\"baboon\")\nplt.subplot(122)\nplt.imshow(cv2.cvtColor(A, cv2.COLOR_BGR2RGB))\nplt.title(\"array A\")\nplt.show()"]},{"cell_type":"markdown","id":"2c0438a5-81a2-4d0a-badc-190906201e84","metadata":{},"outputs":[],"source":["We see they are the same, this is called aliasing. Aliasing happens whenever one variable's value is assigned to another variable because variables are just names that store references to values. We can also compare <code>baboon</code> and array <code>B</code>:\n"]},{"cell_type":"code","id":"6f257664-5124-46a2-93f5-f4a3cbaac980","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\nplt.subplot(121)\nplt.imshow(cv2.cvtColor(baboon, cv2.COLOR_BGR2RGB))\nplt.title(\"baboon\")\nplt.subplot(122)\nplt.imshow(cv2.cvtColor(B, cv2.COLOR_BGR2RGB))\nplt.title(\"array B\")\nplt.show()"]},{"cell_type":"markdown","id":"d9b0626f-b415-48d5-85c9-59ae1339295c","metadata":{},"outputs":[],"source":["\n","They are different because they used the method copy.\n"]},{"cell_type":"markdown","id":"8329fca7-aff3-4ac8-a236-918ffcb05bc1","metadata":{},"outputs":[],"source":["## Fliping Images \n"]},{"cell_type":"markdown","id":"8ef12008-b4ed-4a95-be7c-f9b6fcee8190","metadata":{},"outputs":[],"source":["Flipping images involves reordering the index of the pixels such that it changes the orientation of the image. Consider the following image:\n"]},{"cell_type":"code","id":"58fae8bb-1e01-45f3-be8c-7a6cf55dbd62","metadata":{},"outputs":[],"source":["image = cv2.imread(\"cat.png\")\nplt.figure(figsize=(10,10))\nplt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"markdown","id":"19c04c23-ffd5-489a-afa5-1db59cf1f406","metadata":{},"outputs":[],"source":["We can cast it to an array and find the shape:\n"]},{"cell_type":"code","id":"6b607467-e4cc-4aa6-b390-fcd467550080","metadata":{},"outputs":[],"source":["width, height,C=image.shape\nprint('width, height,C',width, height,C)"]},{"cell_type":"markdown","id":"df779170-ed6d-4a4b-ad4e-d8b8f0848374","metadata":{},"outputs":[],"source":["Let's Flip i.e rotate it vertically. First, we create an array of equal size of type <code>np.uint8</code> bit image.\n"]},{"cell_type":"code","id":"342c91c5-98a3-41d5-a64f-4fa7fa7c6422","metadata":{},"outputs":[],"source":["array_flip = np.zeros((width, height,C),dtype=np.uint8)"]},{"cell_type":"markdown","id":"f9c652c7-29ed-46e3-b886-f902a4ed7f53","metadata":{},"outputs":[],"source":["We assign the first row of pixels of the original array to the new array's last row. We repeat the process for every row, incrementing the row number for the original array and decreasing the new array's row index assigning the pixels accordingly.\n"]},{"cell_type":"code","id":"81acbae0-503e-4b39-b098-cc102f5d75d9","metadata":{},"outputs":[],"source":["for i,row in enumerate(image):\n        array_flip[width-1-i,:,:]=row"]},{"cell_type":"markdown","id":"42160ac9-2557-4474-b68e-e859e33f7aeb","metadata":{},"outputs":[],"source":["We plot the results\n"]},{"cell_type":"code","id":"fe4e4445-a65a-414a-b0ce-9ef6f4e9e5ec","metadata":{},"outputs":[],"source":["plt.figure(figsize=(5,5))\nplt.imshow(cv2.cvtColor(array_flip, cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"markdown","id":"d66c3e78-c3dd-4b31-901d-6e78caf69bfc","metadata":{},"outputs":[],"source":["<code>OpenCV</code>has several ways to flip an image, we can use  the <code>flip()</code> function; we have the input image array. The parameter is the <code>flipCode</code>\n","\n","is the value indicating what kind of flip we would like to perform; \n","<li><code>flipcode</code> = 0: flip vertically around the x-axis</li>\n","<li><code>flipcode</code> > 0: flip horizontally around y-axis positive value</li>\n","<li><code>flipcode</code>&#60 0: flip vertically and horizontally, flipping around both axes negative value</li>\n","Let apply different <code>flipcode</code>'s in a loop:\n"]},{"cell_type":"code","id":"4554ef23-f8d2-4061-bf73-54a10ddcc69e","metadata":{},"outputs":[],"source":["for flipcode in [0,1,-1]:\n    im_flip =  cv2.flip(image,flipcode )\n    plt.imshow(cv2.cvtColor(im_flip,cv2.COLOR_BGR2RGB))\n    plt.title(\"flipcode: \"+str(flipcode))\n    plt.show()"]},{"cell_type":"markdown","id":"dc4205f0-683b-4f46-a70d-83215be3c35e","metadata":{},"outputs":[],"source":["We can also use the <code>rotate()</code> function. The parameter is an integer indicating what kind of flip we would like to perform. \n"]},{"cell_type":"code","id":"9b417ee6-2530-489d-b165-7d5641da05fa","metadata":{},"outputs":[],"source":["im_flip = cv2.rotate(image,0)\nplt.imshow(cv2.cvtColor(im_flip,cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"markdown","id":"767b3df9-8839-4c06-a202-6edfeb2a876f","metadata":{},"outputs":[],"source":["OpenCV module has built-in attributes the describe the type of flip, the values are just integers. Several are shown in the following <code>dict</code>:\n"]},{"cell_type":"code","id":"c3bc8141-8d7f-4e84-9788-d40e94f6cc97","metadata":{},"outputs":[],"source":["flip = {\"ROTATE_90_CLOCKWISE\":cv2.ROTATE_90_CLOCKWISE,\"ROTATE_90_COUNTERCLOCKWISE\":cv2.ROTATE_90_COUNTERCLOCKWISE,\"ROTATE_180\":cv2.ROTATE_180}"]},{"cell_type":"markdown","id":"cdf2ddb3-885a-42f4-affd-d490628e2080","metadata":{},"outputs":[],"source":["We see the keys are just an integer\n"]},{"cell_type":"code","id":"61bf1039-a9bf-4076-b321-7c44072468df","metadata":{},"outputs":[],"source":["flip[\"ROTATE_90_CLOCKWISE\"]"]},{"cell_type":"markdown","id":"0956c7b2-988b-4236-9823-c40818277043","metadata":{},"outputs":[],"source":["We can plot each of the outputs using the different  parameter values \n"]},{"cell_type":"code","id":"347e6b09-57e8-40c5-94d7-0d8441d55212","metadata":{},"outputs":[],"source":["for key, value in flip.items():\n    plt.subplot(1,2,1)\n    plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n    plt.title(\"orignal\")\n    plt.subplot(1,2,2)\n    plt.imshow(cv2.cvtColor(cv2.rotate(image,value), cv2.COLOR_BGR2RGB))\n    plt.title(key)\n    plt.show()"]},{"cell_type":"markdown","id":"2771d3c6-5e55-4824-8e61-e11d4d8041af","metadata":{},"outputs":[],"source":[" ## Cropping an Image\n"]},{"cell_type":"markdown","id":"f0ad0ccb-0f15-41ce-aec8-1b15071f77cc","metadata":{},"outputs":[],"source":["Cropping is \"cutting out\" the part of the image and throwing out the rest; we can crop using arrays. Let start with a vertical crop; the variable <code>upper</code> is the first row that we would like to include in the image, the variable <code>lower</code> is the last row we would like to include. We then use slicing to obtain the new image. \n"]},{"cell_type":"code","id":"a27a25b4-8ff0-4509-bec3-2f82d8653863","metadata":{},"outputs":[],"source":["upper = 150\nlower = 400\ncrop_top = image[upper: lower,:,:]\nplt.figure(figsize=(10,10))\nplt.imshow(cv2.cvtColor(crop_top, cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"markdown","id":"b67d6d76-ea31-4829-a627-1015284a24b5","metadata":{},"outputs":[],"source":["consider the array <code>crop_top</code> we  can also crop horizontally  the variable right is the first column that we would like to include in the image, the variable left is the last column we would like to include in the image.\n"]},{"cell_type":"code","id":"fcfde7e1-df90-42f2-a957-f3b05862a8f2","metadata":{},"outputs":[],"source":["left = 150\nright = 400\ncrop_horizontal = crop_top[: ,left:right,:]\nplt.figure(figsize=(5,5))\nplt.imshow(cv2.cvtColor(crop_horizontal, cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"markdown","id":"bd82fa19-62af-45c8-894f-1a9a8729b7e1","metadata":{},"outputs":[],"source":["## Changing Specific Image Pixels\n"]},{"cell_type":"markdown","id":"c36b32e8-0c77-4f74-bdfa-908dcff09732","metadata":{},"outputs":[],"source":["We can change specific image pixels using  array indexing; for example, we can set  all the channels in the original image we cropped to zero :\n"]},{"cell_type":"code","id":"9ddad9fd-4b64-44e7-ae5f-b001b7ef0a3a","metadata":{},"outputs":[],"source":["array_sq = np.copy(image)\narray_sq[upper:lower,left:right,:] = 0"]},{"cell_type":"markdown","id":"de47e441-ef54-4de9-bfaa-099293d0ebf8","metadata":{},"outputs":[],"source":["We can compare the results to the new image. \n"]},{"cell_type":"code","id":"78a42689-506e-446d-9475-0308fbefd79c","metadata":{},"outputs":[],"source":["plt.figure(figsize=(10,10))\nplt.subplot(1,2,1)\nplt.imshow(cv2.cvtColor(image,cv2.COLOR_BGR2RGB))\nplt.title(\"orignal\")\nplt.subplot(1,2,2)\nplt.imshow(cv2.cvtColor(array_sq,cv2.COLOR_BGR2RGB))\nplt.title(\"Altered Image\")\nplt.show()"]},{"cell_type":"markdown","id":"4164e6bf-8d56-4878-b3bf-e42bd1755710","metadata":{},"outputs":[],"source":["  We can also create shapes and <code>OpenCV</code>, we can use the method <code>rectangle</code>. The parameter  <code>pt1</code> is the top-left coordinate of the rectangle: <code>(left,top)</code> or $(x_0,y_0)$, <code>pt2</code> is the bottom right coordinate<code>(right,lower)</code> or $(x_1,y_1)$. The parameter <code>color</code>  is a tuple representing the intensity of each channel <code>( blue, green, red)</code>. Finally, we have the line thickness.\n"]},{"cell_type":"code","id":"9207fa6b-b719-410f-ab32-b9f42daa580d","metadata":{},"outputs":[],"source":["start_point, end_point = (left, upper),(right, lower)\nimage_draw = np.copy(image)\ncv2.rectangle(image_draw, pt1=start_point, pt2=end_point, color=(0, 255, 0), thickness=3) \nplt.figure(figsize=(5,5))\nplt.imshow(cv2.cvtColor(image_draw, cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"markdown","id":"fb30943e-6290-41e9-9526-395e524d4c12","metadata":{},"outputs":[],"source":["We can overlay text on an image using the function  <code>putText</code> with the following parameter values:\n"]},{"cell_type":"markdown","id":"8544ef05-695f-415a-83d0-c50a25cdf3b7","metadata":{},"outputs":[],"source":["\n"," <li><code>img</code>: Image array </li>\n","<li><code>text</code>: Text string to be overlayed</li>\n","<li><code>org</code>: Bottom-left corner of the text string in the image</li>\n","<li><code>fontFace</code>: tye type of font </li>\n","<li><code>fontScale</code>: Font scale</li>\n","<li><code>color</code>: Text color</li>\n","<li><code>thickness</code>: Thickness of the lines used to draw a text</li>\n","<li><code>lineType:</code> Line type</li>\n"]},{"cell_type":"code","id":"a2a75c09-3969-4b8c-b01b-a9596fe883e8","metadata":{},"outputs":[],"source":["image_draw=cv2.putText(img=image,text='Stuff',org=(10,500),color=(255,255,255),fontFace=4,fontScale=5,thickness=2)\nplt.figure(figsize=(10,10))\nplt.imshow(cv2.cvtColor(image_draw,cv2.COLOR_BGR2RGB))\nplt.show()"]},{"cell_type":"markdown","id":"827dd1d4-90bf-4d1b-bc6c-248f7b4b8650","metadata":{},"outputs":[],"source":["### Question-4: \n","Use the image baboon.png from this lab or take any image you like.\n","\n","Open the image and create a OpenCV Image object called `im`, convert the image from BGR format to RGB format, flip `im` vertically around the x-axis and create an image called `im_flip`, mirror `im` by flipping it horizontally around the y-axis and create an image called `im_mirror`, finally plot both images\n"]},{"cell_type":"code","id":"02f8ef80-8a98-4899-a969-7f7418ff1975","metadata":{},"outputs":[],"source":["# write your code here\n"]},{"cell_type":"markdown","id":"5b9f5a8d-aa36-42da-9220-19a5e007dbb6","metadata":{},"outputs":[],"source":["Double-click **here** for a hint.\n","\n","<!-- The hint is below:\n","\n","im_flip =  cv2.flip(baboon,0)\n","im_mirror =  cv2.flip(baboon, 1)\n","\n","-->\n"]},{"cell_type":"markdown","id":"d8317ae1-880d-427c-a169-d6edff3a1e77","metadata":{},"outputs":[],"source":["Double-click **here** for the solution.\n","\n","<!-- The answer is below:\n","\n","im = cv2.imread(\"baboon.png\")\n","\n","im_flip =  cv2.flip(im, 0)\n","plt.imshow(cv2.cvtColor(im_flip, cv2.COLOR_BGR2RGB))\n","plt.show()\n","\n","im_mirror =  cv2.flip(im, 1)\n","plt.imshow(cv2.cvtColor(im_mirror, cv2.COLOR_BGR2RGB))\n","plt.show()\n","\n","-->\n"]},{"cell_type":"markdown","id":"c250e6cb-e8ef-441d-814d-13714f6329ca","metadata":{},"outputs":[],"source":["<h2>Authors</h2>\n"]},{"cell_type":"markdown","id":"a55de1f7-8ac0-4a02-b236-af2fcd396697","metadata":{},"outputs":[],"source":[" [Joseph Santarcangelo]( https://www.linkedin.com/in/joseph-s-50398b136/) has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n"]},{"cell_type":"markdown","id":"64597138-99a2-468c-a361-33628809e40b","metadata":{},"outputs":[],"source":["[Nayef Abou Tayoun](https://www.linkedin.com/in/nayefaboutayoun/) has a master of management in artificial intelligence degree, focusing on using machine learning and computer vision.\n"]},{"cell_type":"markdown","id":"f81919c8-7a38-46b1-a24a-f01723746784","metadata":{},"outputs":[],"source":["# References \n"]},{"cell_type":"markdown","id":"9d3930b0-f4b7-4e4c-84bd-c1b35e136372","metadata":{},"outputs":[],"source":["[1]  Images were taken from: https://homepages.cae.wisc.edu/~ece533/images/\n","    \n","[2]  <a href='https://pillow.readthedocs.io/en/stable/index.html'>Pillow Docs</a>\n","\n","[3]  <a href='https://opencv.org/'>Open CV</a>\n","\n","[4] Gonzalez, Rafael C., and Richard E. Woods. \"Digital image processing.\" (2017).\n"]},{"cell_type":"markdown","id":"fc69c644-08ad-4017-9ae0-10037377e590","metadata":{},"outputs":[],"source":["<!--<h2>Change Log</h2>-->\n"]},{"cell_type":"markdown","id":"61471329-9df9-40b8-854a-38b58b2667ba","metadata":{},"outputs":[],"source":["<!--\n","<table>\n","    <tr>\n","        <th>Date (YYYY-MM-DD)</th>\n","        <th>Version</th>\n","        <th>Changed By</th>\n","        <th>Change Description</th>\n","    </tr>\n","    <tr>\n","        <td>2020-07-20</td>\n","        <td>0.2</td>\n","        <td>Azim</td>\n","        <td>Modified Multiple Areas</td>\n","    </tr>\n","    <tr>\n","        <td>2020-07-17</td>\n","        <td>0.1</td>\n","        <td>Azim</td>\n","        <td>Created Lab Template</td>\n","    </tr>\n","    <tr>\n","        <td>2021-03-06</td>\n","        <td>0.3</td>\n","        <td>Nayef</td>\n","        <td>Modified some codes</td>\n","    </tr>\n","</table>\n","-->\n"]},{"cell_type":"markdown","id":"a8de0d9a-de30-423b-aee6-b26dc17230c1","metadata":{},"outputs":[],"source":["<h3 align=\"center\"> &#169; IBM Corporation. All rights reserved. <h3/>\n"]}],"metadata":{"kernelspec":{"display_name":"Python","language":"python","name":"conda-env-python-py"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"prev_pub_hash":"6a90ffb7aed50528984281a7d2d8fb05d3512961684d2f4d202df1f92b7955c1"},"nbformat":4,"nbformat_minor":4}